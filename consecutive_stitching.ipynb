{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "1. Get pictures\n",
    "2. Get features\n",
    "3. Do matching\n",
    "4. Get model via RANSAC\n",
    "5. Compensations (improvements, a-la gain compensation etc)\n",
    "6. Stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv version: 4.2.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(f'opencv version: {cv2.__version__}')\n",
    "\n",
    "import numpy as np\n",
    "np.seterr(all='raise')\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "from math import log\n",
    "import glob\n",
    "import os.path as osp\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get pictures\n",
    "1. get \n",
    "2. convert to gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pictures_video_framing():\n",
    "    pass\n",
    "\n",
    "def get_pictures_path(path_source, ext_pattern = \"*.jpeg\"):\n",
    "    images = glob.glob(osp.join(path_source, ext_pattern))\n",
    "    images.sort()\n",
    "    return images\n",
    "\n",
    "def imread_img_gray(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img, gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = get_pictures_path(\"pictures_to_stitch_2\",)\n",
    "img0, gray0 = imread_img_gray(imgs[0])\n",
    "img1, gray1 = imread_img_gray(imgs[1])\n",
    "# print(imgs)\n",
    "# print('img',img, 'gray',gray, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get features\n",
    "1. create detectors\n",
    "2. get key points & descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kp_des(gray, detector):\n",
    "    kp, des = detector.detectAndCompute(gray, None)\n",
    "    return kp, des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create(500) # limit feature points to 500\n",
    "surf = cv2.xfeatures2d.SURF_create() # Hessian threshold is default\n",
    "orb = cv2.ORB_create(nfeatures=500) # limit feature points to 500\n",
    "\n",
    "detector = sift\n",
    "kp_0, des_0 = get_kp_des(gray0, detector)\n",
    "kp_1, des_1 = get_kp_des(gray1, detector)\n",
    "# print('kp_0',kp_0, 'des_0',des_0, sep=\"\\n\")\n",
    "# print('kp_1',kp_1, 'des_1',des_1, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(kp_0[0].convert.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_kp_0 = kp_0[0].convert(kp_0)\n",
    "len(p_kp_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "des_0[0].__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(des_0[0].compress.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Do matching\n",
    "1. Lowe criteria (ratio of the distance to the two closest matching features)\n",
    "2. two-sided matching\n",
    "3. prepare for RANSAC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(des_0, des_1, dist_ratio = 0.7):\n",
    "    \"\"\" \n",
    "    For each descriptor in the first image, select its match in the second image.\n",
    "    \n",
    "    Input: \n",
    "        \"des_0\" - descriptors for the first image\n",
    "        \"des_1\" - same for second image \n",
    "        \"dist_ratio\" - empiric coefficient for Lowe criteria\n",
    "    \n",
    "    Return: \n",
    "        \"matchscores\" - list of indexes for points from the 2nd picture for every position (kp number) in first\n",
    "        e.g: matchscores[0] = 1 means that for the first key point in the 1st image the closest is \n",
    "                                the second key point in the 2nd image\n",
    "    \"\"\"\n",
    "    \n",
    "#     assert des_0.shape[0]==des_1.shape[0], \"Error: des_0 & des_1 has different sizes\"\n",
    "    \n",
    "    des_0_size = des_0.shape[0]\n",
    "    \n",
    "    matchscores = [-1] * des_0_size\n",
    "    \n",
    "    for i, p in enumerate(des_0):\n",
    "        distances = list(map(lambda x: np.linalg.norm(x - p), des_1))\n",
    "        idx = np.argsort(distances)\n",
    "        if distances[idx[0]] < dist_ratio * distances[idx[1]]:\n",
    "            matchscores[i] = idx[0]\n",
    "    return matchscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_twosided(des_0,des_1):   \n",
    "    \"\"\" Two-sided symmetric version of match() - see above \"\"\"\n",
    "    \n",
    "    matches_1_to_2 = np.array(match(des_0, des_1))\n",
    "    matches_2_to_1 = np.array(match(des_1, des_0))\n",
    "    \n",
    "    # remove matches that are not symmetric\n",
    "    for i, n in enumerate(matches_1_to_2):\n",
    "        if n == -1:\n",
    "            continue\n",
    "        if matches_2_to_1[n] != i:\n",
    "            matches_1_to_2[i] = -1\n",
    "    \n",
    "    return matches_1_to_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_to_mutual_corr_list(matches_1_to_2):\n",
    "    ''' Adapt for RANSAC fuction format: [# from 1st, # from 2nd image]'''\n",
    "    mutual_corr_list = []\n",
    "    for indx, match in enumerate(matches_1_to_2):\n",
    "        if match != -1:\n",
    "            mutual_corr_list.append([indx, match])  #[key point from 1st image, same from 2nd]\n",
    "    return mutual_corr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_1_to_2 = match_twosided(des_0,des_1)\n",
    "# print(matches_1_to_2)\n",
    "mutual_corr_list = matches_to_mutual_corr_list(matches_1_to_2)\n",
    "print(mutual_corr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get model via RANSAC\n",
    "1. sampling\n",
    "2. determine error\n",
    "3. iterations required\n",
    "4. determine inliers\n",
    "5. find homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.cse.yorku.ca/~kosta/CompVis_Notes/ransac.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints_pt_by_sample(kp_0,kp_1,sample):\n",
    "    '''\n",
    "    Given list of points, return list of their coordinates to calculate homography matrix\n",
    "    '''\n",
    "    kp_0_sample=[]\n",
    "    kp_1_sample=[]\n",
    "    for i,j in sample:\n",
    "        kp_0_sample.append(kp_0[i].pt)\n",
    "        kp_1_sample.append(kp_1[j].pt)\n",
    "    return kp_0_sample, kp_1_sample\n",
    "\n",
    "def if_2_vectors_collinear(vec1,vec2,eps = 1e-6):\n",
    "    if_collinear = False\n",
    "    vec1_norm = np.linalg.norm(vec1)\n",
    "    vec2_norm = np.linalg.norm(vec2)\n",
    "    if vec1_norm>eps and vec2_norm>eps: \n",
    "        vec_dot = np.dot(vec1,vec2)/vec1_norm/vec2_norm\n",
    "        if abs(vec_dot-1)<=eps:\n",
    "            if_collinear = True\n",
    "    return if_collinear\n",
    "\n",
    "def if_3collinear_in_set(sample_set, kp, eps = 1e-6):\n",
    "    '''\n",
    "    check if any 3 points in a set (e.g. 4 points for homograpy) is collinear\n",
    "    which is inappropriate to find homography matrix\n",
    "    \n",
    "    Through dot product for 2 dimensional.\n",
    "    p.s.: cos(0 grad) = 1 :)\n",
    "    eps (by def) = 10^(-6)\n",
    "    \n",
    "    Input:\n",
    "        'sample_set' - 4 points from 1 image to find homography matrix\n",
    "        'kp' - key points from set\n",
    "        'eps' - accuracy, 10^(-6) by default\n",
    "    \n",
    "    Return:\n",
    "        'if_collinear' - boolean if there is a 3 point on one line\n",
    "    '''\n",
    "    \n",
    "    # get points from kp\n",
    "    points = []\n",
    "    for point_num in sample_set:\n",
    "        points.append(kp[point_num])\n",
    "    \n",
    "    # for each combination of 3 points find collinear\n",
    "    if_collinear = False\n",
    "    for three_points in itertools.combinations(points,3):\n",
    "        vec1 = np.array(three_points[1].pt)-np.array(three_points[0].pt)\n",
    "        vec2 = np.array(three_points[2].pt)-np.array(three_points[0].pt)\n",
    "        \n",
    "        if_collinear = if_2_vectors_collinear(vec1,vec2,eps)\n",
    "        if if_collinear:\n",
    "            break\n",
    "    return if_collinear\n",
    "\n",
    "def get_4_different_pairs(mutual_corr_list, kp_0, kp_1):\n",
    "    sample_set_1 = set()\n",
    "    sample_set_2 = set()\n",
    "    \n",
    "    while True:\n",
    "        sample = random.sample(mutual_corr_list,4)\n",
    "        sample_set_1.clear()\n",
    "        sample_set_2.clear()\n",
    "        for i,j in sample:\n",
    "            sample_set_1.add(i)\n",
    "            sample_set_2.add(j)\n",
    "        if len(sample_set_1) ==4 and len(sample_set_2)==4: \n",
    "            if not if_3collinear_in_set(sample_set_1, kp_0) and not if_3collinear_in_set(sample_set_2, kp_1):\n",
    "                break\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_by_angle(vec_0,vec_1): \n",
    "    ''' \n",
    "    If we use distance as angle between 2 vectors.\n",
    "    But it's not a common metrics\n",
    "    '''\n",
    "\n",
    "    vec_0_norm = vec_0/np.linalg.norm(vec_0)\n",
    "    vec_1_norm = vec_1/np.linalg.norm(vec_1)\n",
    "    \n",
    "    cross_prod = np.dot(vec_0_norm,vec_1_norm.T)\n",
    "    \n",
    "    distance_angle = np.arccos(cross_prod)\n",
    "    \n",
    "    return distance_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ransac_req_iter_num(e=0.5,s=4,p=0.99):\n",
    "    \"\"\"\n",
    "    [N] - max number of iterations is determined to ensure that the probability (p),\n",
    "    that at least one of the sets of random selected samples doesn't include outlier. \n",
    "    \n",
    "    [1-p = (1-(1-e)^m)^N] -> [N = log(1-p)/log(1-(1-e)^s)]\n",
    "    \n",
    "    [e] - probability that a point is an outlier\n",
    "    [s] - minimum required number of points in the sample: 4 pairs is for computing homography (1 pair is one point)\n",
    "    [p] - desired probability that at least one of the sets of random selected samples doesn't include outlier\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    iter_num_required = log(1-p)/log(1-(1-e)**s)\n",
    "    req_iter = int(iter_num_required)+1\n",
    "    return req_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inliers(h, sample, kp_0, kp_1, mutual_corr_list, threshold, dist=\"norm\"):\n",
    "    '''\n",
    "    calculate inliers for all points from mutual_corr_list\n",
    "    using \n",
    "    '''\n",
    "    appropriate = []\n",
    "    total_distance = 0\n",
    "    for i,j in mutual_corr_list:\n",
    "        kp_1_h = h.dot(np.array((kp_1[j].pt[0], kp_1[j].pt[1], 1), dtype = \"float64\"))\n",
    "        kp_1_h /= kp_1_h[2]\n",
    "        kp_0_orig = np.array((kp_0[i].pt[0], kp_0[i].pt[1], 1), dtype = \"float64\")\n",
    "        \n",
    "        if dist == 'norm':\n",
    "            distance = cv2.norm(kp_1_h - kp_0_orig)\n",
    "        else:\n",
    "            distance = dist_by_angle(kp_0_h,kp_1_orig)\n",
    "        \n",
    "        if distance <= threshold:\n",
    "            appropriate.append(distance)\n",
    "            \n",
    "        total_distance += distance\n",
    "        \n",
    "    return len(appropriate), total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac_find_homography_matrix(kp_0, kp_1, mutual_corr_list,threshold, iter_num_required=0,\n",
    "                                  dist = 'norm'):\n",
    "    '''\n",
    "    0) calculate required number of iterations\n",
    "    repeat for required number of iterations:\n",
    "    1) get sample of kps\n",
    "    2) calculate Homography matrix\n",
    "    3) calculate inliers & total error\n",
    "    4) save the matrix with higher number of matchinliers & lower total error\n",
    "    '''\n",
    "    # 0\n",
    "    if iter_num_required == 0:\n",
    "        iter_num_required = get_ransac_req_iter_num()\n",
    "    # print(kp_0)\n",
    "    # kp_0 = np.array([kp_0[i].pt for i, _ in mutual_corr_list])\n",
    "    # kp_1 = np.array([kp_1[i].pt for _, i in mutual_corr_list])\n",
    "    # best_homography, _ = cv2.findHomography(kp_1, kp_0, cv2.RANSAC, threshold)\n",
    "\n",
    "    best_homography = []\n",
    "    max_inliers_num = -1 \n",
    "    total_error_min = -1\n",
    "    for x in range(iter_num_required):\n",
    "        # 1\n",
    "        sample = get_4_different_pairs(mutual_corr_list, kp_0, kp_1)\n",
    "        kp_0_sample, kp_1_sample = get_keypoints_pt_by_sample(kp_0,kp_1,sample)\n",
    "        # 2\n",
    "        # get matrix h to warp right image to the left: kp_1 - source, kp_0 - destination\n",
    "        h, status = cv2.findHomography(np.array(kp_1_sample), np.array(kp_0_sample), 10**6)\n",
    "        # 3\n",
    "        curr_inliers_num, total_error = get_inliers(h,sample,kp_0,kp_1,mutual_corr_list,threshold, dist)\n",
    "        \n",
    "        if_equal_inliers_less_error = max_inliers_num == curr_inliers_num \\\n",
    "                                      and total_error_min!=-1 and total_error_min>total_error\n",
    "        if max_inliers_num < curr_inliers_num or if_equal_inliers_less_error:\n",
    "#             print(f'Change of model!!!', \n",
    "#                   f'Previous max_inliers_num: {max_inliers_num}',\n",
    "#                   f'Previous total_error_min: {total_error_min}',\n",
    "#                   f'Current curr_inliers_num: {curr_inliers_num}',\n",
    "#                   f'Current total_error: {total_error}',\n",
    "#                   sep = '\\n')\n",
    "            max_inliers_num = curr_inliers_num\n",
    "            total_error_min = total_error\n",
    "            best_homography = h\n",
    "        \n",
    "    print(f'Number of iterations: {iter_num_required}',\n",
    "          f'Maximum inliers: {max_inliers_num}',\n",
    "          f'Total error min: {total_error_min}', \n",
    "          f'Best homography: {best_homography}', \n",
    "          sep = '\\n')\n",
    "    return max_inliers_num, total_error_min, best_homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold = 4\n",
    "inliers, error, h = ransac_find_homography_matrix(kp_0, kp_1, mutual_corr_list, \n",
    "                                                  threshold, iter_num_required=0, dist = \"norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compensations (improvements, a-la gain compensation etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix h is to warp right image to the left: kp_1 - source, kp_0 - destination\n",
    "def warp_n_stitch_imgs(h, img0, img1): #, path_results, path_source):\n",
    "    if np.all(h) != 0: \n",
    "        img_1_after_homography = img1.copy()\n",
    "        img_0_ext = cv2.copyMakeBorder(img0, \n",
    "                                       0, 0, 0, img_1_after_homography.shape[1], \n",
    "                                       cv2.BORDER_CONSTANT, (0,0,0))\n",
    "        result_img_length = img0.shape[1]+img1.shape[1]\n",
    "        result_img_height = img1.shape[0]\n",
    "        result_img = cv2.warpPerspective(img_1_after_homography, h, \n",
    "                                         (result_img_length, result_img_height), \n",
    "                                         img_0_ext,\n",
    "                                         borderMode = cv2.BORDER_TRANSPARENT)\n",
    "#         result_img[:img0.shape[0], :img0.shape[1]] = img0\n",
    "#         result_imwrite = cv2.imwrite(os.path.join(path_results,'warped',f'{path_source}_sift.jpg'),result_img)\n",
    "        return result_img\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results = \"results\"\n",
    "path_source = \"pictures_to_stitch_2\"\n",
    "img_1_after_homography = img1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_0_ext = cv2.copyMakeBorder(img0,0,0,0,img0.shape[1],cv2.BORDER_CONSTANT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_img_length = img0.shape[1]*2\n",
    "result_img_height = img1.shape[0]\n",
    "result_img = cv2.warpPerspective(img_1_after_homography, h, \n",
    "                                 (result_img_length,result_img_height),\n",
    "                                 img_0_ext,\n",
    "                                 borderMode=cv2.BORDER_TRANSPARENT)\n",
    "result_imwrite = cv2.imwrite(os.path.join(path_results,'warped',f'{path_source}_sift_transparent.jpg'),result_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_source = \"pictures_to_stitch_2\"\n",
    "\n",
    "imgs = get_pictures_path(path_source)\n",
    "img0, gray0 = imread_img_gray(imgs[0])\n",
    "img1, gray1 = imread_img_gray(imgs[1])\n",
    "sift = cv2.xfeatures2d.SIFT_create(500) # limit feature points to 500\n",
    "surf = cv2.xfeatures2d.SURF_create() # Hessian threshold is default\n",
    "orb = cv2.ORB_create(nfeatures=500) # limit feature points to 500\n",
    "detector = sift\n",
    "kp_0, des_0 = get_kp_des(gray0, detector)\n",
    "kp_1, des_1 = get_kp_des(gray1, detector)\n",
    "matches_1_to_2 = match_twosided(des_0,des_1)\n",
    "# print(matches_1_to_2)\n",
    "mutual_corr_list = matches_to_mutual_corr_list(matches_1_to_2)\n",
    "# print(mutual_corr_list)\n",
    "threshold = 4\n",
    "inliers, error, h = ransac_find_homography_matrix(kp_0, kp_1, mutual_corr_list, \n",
    "                                                  threshold, iter_num_required=0, dist = \"norm\")\n",
    "result_img = warp_n_stitch_imgs(h, img0, img1)\n",
    "\n",
    "path_results = \"results\"\n",
    "\n",
    "result_imwrite = cv2.imwrite(os.path.join(path_results,'warped',f'{path_source}_sift.jpg'),result_img)\n",
    "\n",
    "print(result_imwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive_stitching(path_to_imgs, detector, threshold=4):\n",
    "    imgs = get_pictures_path(path_to_imgs)\n",
    "    h_total = np.array([0,])\n",
    "    for i in range(len(imgs)-1):\n",
    "        img0, gray0 = imread_img_gray(imgs[i])\n",
    "        img1, gray1 = imread_img_gray(imgs[i+1])\n",
    "        kp_0, des_0 = get_kp_des(gray0, detector)\n",
    "        kp_1, des_1 = get_kp_des(gray1, detector)\n",
    "        matches_1_to_2 = match_twosided(des_0,des_1)\n",
    "        mutual_corr_list = matches_to_mutual_corr_list(matches_1_to_2)\n",
    "        inliers, error, h = ransac_find_homography_matrix(kp_0, kp_1, mutual_corr_list, \n",
    "                                                  threshold, iter_num_required=0, dist = \"norm\")\n",
    "        if h_total.all() ==0:\n",
    "            h_total = h\n",
    "            result_img = warp_n_stitch_imgs(h_total, img0, img1)\n",
    "        else:\n",
    "            h_total = h.dot(h_total)\n",
    "            result_img = warp_n_stitch_imgs(h_total, result_img, img1)          \n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 72\n",
      "Maximum inliers: 38\n",
      "Total error min: 1001.8419337088656\n",
      "Best homography: [[ 8.05714439e-01 -1.85982517e-02  3.81392970e+02]\n",
      " [-2.00330303e-01  9.54930764e-01  2.64136549e+01]\n",
      " [-3.27608432e-04 -2.44878327e-06  1.00000000e+00]]\n",
      "Number of iterations: 72\n",
      "Maximum inliers: 42\n",
      "Total error min: 2425.222740073378\n",
      "Best homography: [[ 8.30332685e-01 -2.13268199e-02  3.93199490e+02]\n",
      " [-2.28754179e-01  9.70691934e-01 -2.31938765e+00]\n",
      " [-3.78617581e-04  1.08082920e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "path_source = \"pictures_to_stitch_2\"\n",
    "path_results = \"results\"\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create(500) # limit feature points to 500\n",
    "surf = cv2.xfeatures2d.SURF_create() # Hessian threshold is default\n",
    "orb = cv2.ORB_create(nfeatures=500) # limit feature points to 500\n",
    "\n",
    "result_img_consecutive = consecutive_stitching(path_source, sift, 4)\n",
    "\n",
    "result_imwrite = cv2.imwrite(os.path.join(path_results,'warped',f'{path_source}_total_sift.jpg'),result_img_consecutive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
