{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.1-dev\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "from math import log\n",
    "import glob\n",
    "import os.path as osp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_source = \"pictures_to_stitch_2\"\n",
    "images = glob.glob(osp.join(path_source, \"*.jpeg\"))\n",
    "images.sort()\n",
    "path_results = \"results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pictures_to_stitch_2\\\\001.jpeg', 'pictures_to_stitch_2\\\\002.jpeg', 'pictures_to_stitch_2\\\\003.jpeg']\n"
     ]
    }
   ],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions: Downscale, Read (many) --> img(s), gray(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale_img(img,scale_factor):\n",
    "    '''\n",
    "    Downscale image by a scale factor using INTER_AREA interpolation. \n",
    "    \n",
    "    Input: img - original image, \n",
    "           scale_factor - scale factor, by which height and width will be multiplied (e.g. 50/100=0,5)\n",
    "           \n",
    "    Return: img_s - downscaled image\n",
    "    '''\n",
    "    img_s = img.copy()\n",
    "    if len(img_s.shape)==3:\n",
    "        height, width, depth = img_s.shape\n",
    "    if len(img_s.shape)==2:\n",
    "        height, width = img_s.shape\n",
    "    dim_s = (int(width*scale_factor),int(height*scale_factor)) \n",
    "#     print('Original dim: {}, Scale factor: {}'.format(img_s.shape,scale_factor))\n",
    "#     print('After resize dim: {}'.format(dim_s))\n",
    "    img_s = cv2.resize(img_s, dim_s, interpolation = cv2.INTER_AREA)\n",
    "    return img_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread_img_gray(folder, file, scale_factor):\n",
    "    '''\n",
    "    Read one specific image file (\"file\") from a specific folder (\"folder\") \n",
    "    scale it by \"scale_factor\" (e.g. 50/100=0,5)\n",
    "    and convert BGR to Gray.\n",
    "    \n",
    "    Input: \"folder\" - absolute path to folder with images,\n",
    "           \"file\" - name of the file to read,\n",
    "           \"scale_factor\" - scale factor, by which height and width will be multiplied (e.g. 50/100=0,5)\n",
    "        \n",
    "    Return: \"img\" - scaled image, \n",
    "            \"gray\" - scaled gray image\n",
    "    '''\n",
    "    img = cv2.imread(os.path.join(folder,file))\n",
    "    img = downscale_img(img,scale_factor)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img, gray\n",
    "\n",
    "def batch_imread_imgs_grays(files,scale_factor):\n",
    "    '''\n",
    "    Read many specific image files (\"files\") from a specific folder (\"folder\") \n",
    "    scale it by \"scale_factor\" (e.g. 50/100=0,5)\n",
    "    and convert BGR to Gray.\n",
    "    \n",
    "    Input: \"folder\" - absolute path to folder with images,\n",
    "           \"files\" - list of files' names to read,\n",
    "           \"scale_factor\" - scale factor, by which height and width will be multiplied (e.g. 50/100=0,5)\n",
    "        \n",
    "    Return: \"imgs\" - list of scaled images, \n",
    "            \"grays\" - list of scaled gray images\n",
    "    '''\n",
    "    imgs = []\n",
    "    grays = []\n",
    "    for file in files:\n",
    "        img = cv2.imread(os.path.join(file))\n",
    "#         img = downscale_img(img,scale_factor)\n",
    "        imgs.append(img)\n",
    "        grays.append(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    return imgs, grays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and Prepare imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, grays = batch_imread_imgs_grays(images, 50/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of Box stitching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "stitcher = cv2.Stitcher_create()\n",
    "status, result_img = stitcher.stitch(imgs)\n",
    "\n",
    "if status == 0:\n",
    "    cv2.imwrite(os.path.join(absolute_path_results,'out_of_box','pano_sift.jpg'),result_img)\n",
    "else:\n",
    "    print(\"Status: {}\".format(status))\n",
    "for n, img in enumerate(imgs):\n",
    "    cv2.imwrite(os.path.join(absolute_path_results,'out_of_box','img{}_s.jpg'.format(n)),img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create(500) # limit feature points to 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SURF detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = cv2.xfeatures2d.SURF_create() # Hessian threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORB detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create(nfeatures=500) # limit feature points to 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get KeyPoints and Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kp_des(gray, detector):\n",
    "    kp, des = detector.detectAndCompute(gray, None)\n",
    "    return kp, des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN PROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get KeyPoints & Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_0, des_0 = get_kp_des(grays[1], detector)\n",
    "kp_1, des_1 = get_kp_des(grays[2], detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img0_kp = imgs[0].copy()\n",
    "img0_kp = cv2.drawKeypoints(img0_kp,kp_0,img0_kp, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite(os.path.join(path_results,'key_points','img000_sift.jpg'),img0_kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1_kp = imgs[1].copy()\n",
    "img1_kp = cv2.drawKeypoints(img1_kp,kp_1,img1_kp, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite(os.path.join(path_results,'key_points','img001_sift.jpg'),img1_kp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Lowe criteria for points matching\n",
    "A robust criteria (also introduced by Lowe) for matching a feature in one image to a\n",
    "feature in another image is to use the ratio of the distance to the two closest matching\n",
    "features. This ensures that only features that are distinct enough compared to the\n",
    "other features in the image are used. As a consequence, the number of false matches\n",
    "is lowered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(des_0, des_1, dist_ratio = 0.7):\n",
    "    \"\"\" \n",
    "    For each descriptor in the first image, select its match in the second image.\n",
    "    Idea - use the angle between descriptor vectors (normalised) as distance measure.\n",
    "    \n",
    "    Input: \n",
    "        \"des_0\" - descriptors for the first image\n",
    "        \"des_1\" - same for second image \n",
    "    \n",
    "    Return: \n",
    "        \"matchscores\" - list of indexes for points from the 2nd picture for every position (kp number) in first\n",
    "        e.g: matchscores[0] = 1 means that for the first key point in the 1st image the closest is second in the 2nd image\n",
    "    \"\"\"\n",
    "    \n",
    "    # des_0 = np.array(des_0, dtype=np.float64)\n",
    "    # des_1 = np.array(des_1, dtype=np.float64)\n",
    "    \n",
    "    des_0_size = des_0.shape[0]\n",
    "    \n",
    "    matchscores = [-1] * des_0_size\n",
    "    \n",
    "    # des_1_T = des_1.T # precompute matrix transpose\n",
    "    \n",
    "    # for i in range(des_0_size[0]):  \n",
    "    #     dotprods = np.dot(des_0[i,:],des_1_T) # vector of dot products\n",
    "    #     dotprods = 0.9999*dotprods\n",
    "    #     # inverse cosine and sort ascending, return index for features in second image \n",
    "    #     # https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html\n",
    "    #     indx = np.argsort(np.arccos(dotprods))\n",
    "    #     # check if nearest neighbor has angle less than dist_ratio times 2nd\n",
    "    #     if np.arccos(dotprods)[indx[0]] < dist_ratio * np.arccos(dotprods)[indx[1]]:\n",
    "    #         matchscores[i] = int(indx[0])\n",
    "    for i, p in enumerate(des_0):\n",
    "        distances = list(map(lambda x: np.linalg.norm(x - p), des_1))\n",
    "        idx = np.argsort(distances)\n",
    "        if distances[idx[0]] < dist_ratio * distances[idx[1]]:\n",
    "            matchscores[i] = idx[0]\n",
    "    return matchscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKIPPED SECOND MATCH ON PURPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_twosided(des_0,des_1):\n",
    "    \n",
    "    \"\"\" Two-sided symmetric version of match() - see above \"\"\"\n",
    "    \n",
    "    matches_1_to_2 = match(des_0, des_1)\n",
    "    # matches_2_to_1 = match(des_1, des_0)\n",
    "    \n",
    "    # print(matches_1_to_2.reshape((matches_1_to_2.shape[0],)))\n",
    "    # print(matches_2_to_1.reshape((matches_2_to_1.shape[0],)))\n",
    "    # remove matches that are not symmetric\n",
    "    # for i, n in enumerate(matches_1_to_2):\n",
    "    #     if n == -1:\n",
    "    #         continue\n",
    "    #     if matches_2_to_1[n] != i:\n",
    "    #         matches_1_to_2[i] = -1\n",
    "    \n",
    "    return matches_1_to_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_1_to_2 = match_twosided(des_0,des_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1,\n",
       " 175,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 210,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 114,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 230,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 231,\n",
       " -1,\n",
       " 119,\n",
       " -1,\n",
       " -1,\n",
       " 232,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 235,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 340,\n",
       " -1,\n",
       " 340,\n",
       " 254,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 255,\n",
       " 256,\n",
       " -1,\n",
       " -1,\n",
       " 258,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 327,\n",
       " 98,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 273,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 285,\n",
       " -1,\n",
       " 286,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 180,\n",
       " 183,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 126,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 122,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 179,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 268,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 268,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 156,\n",
       " 162,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 137,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 86,\n",
       " -1,\n",
       " 85,\n",
       " 217,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 123,\n",
       " -1,\n",
       " -1,\n",
       " 228,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 122,\n",
       " 241,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 98,\n",
       " -1,\n",
       " 259,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 257,\n",
       " -1,\n",
       " -1,\n",
       " 470,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 195,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 30,\n",
       " 158,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 72,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 194,\n",
       " 193,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 84,\n",
       " -1,\n",
       " -1,\n",
       " 364,\n",
       " 288,\n",
       " 288,\n",
       " 296,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 436,\n",
       " -1,\n",
       " 0,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 26,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 38,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 283,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 29,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 270,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 59,\n",
       " 270,\n",
       " -1,\n",
       " 31,\n",
       " -1,\n",
       " -1,\n",
       " 289,\n",
       " -1,\n",
       " -1,\n",
       " 334,\n",
       " 160,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 159,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 253,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 265,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 149,\n",
       " 244,\n",
       " -1,\n",
       " 244,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 154,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 245,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 364,\n",
       " 310,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 266,\n",
       " -1,\n",
       " -1,\n",
       " 187,\n",
       " 185,\n",
       " -1,\n",
       " -1,\n",
       " 325,\n",
       " 234,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 201,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 374,\n",
       " 359,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_1_to_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_to_mutual_corr_list(matches_1_to_2):\n",
    "    ''' Adapt for RANSAC fuction format: [# from 1st, # from 2nd image]'''\n",
    "    mutual_corr_list = []\n",
    "    for indx, match in enumerate(matches_1_to_2):\n",
    "        if match != -1:\n",
    "            mutual_corr_list.append([indx, match])  #[key point from 1st image, same from 2nd]\n",
    "    return mutual_corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_corr_list = matches_to_mutual_corr_list(matches_1_to_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 175],\n",
       " [5, 210],\n",
       " [19, 114],\n",
       " [53, 230],\n",
       " [61, 231],\n",
       " [63, 119],\n",
       " [66, 232],\n",
       " [71, 235],\n",
       " [87, 340],\n",
       " [89, 340],\n",
       " [90, 254],\n",
       " [94, 255],\n",
       " [95, 256],\n",
       " [98, 258],\n",
       " [106, 327],\n",
       " [107, 98],\n",
       " [117, 273],\n",
       " [131, 285],\n",
       " [133, 286],\n",
       " [159, 180],\n",
       " [160, 183],\n",
       " [166, 126],\n",
       " [170, 122],\n",
       " [175, 179],\n",
       " [180, 268],\n",
       " [188, 268],\n",
       " [195, 156],\n",
       " [196, 162],\n",
       " [201, 137],\n",
       " [206, 86],\n",
       " [208, 85],\n",
       " [209, 217],\n",
       " [216, 123],\n",
       " [219, 228],\n",
       " [225, 122],\n",
       " [226, 241],\n",
       " [233, 98],\n",
       " [235, 259],\n",
       " [240, 257],\n",
       " [243, 470],\n",
       " [250, 195],\n",
       " [258, 30],\n",
       " [259, 158],\n",
       " [276, 72],\n",
       " [284, 194],\n",
       " [285, 193],\n",
       " [294, 84],\n",
       " [297, 364],\n",
       " [298, 288],\n",
       " [299, 288],\n",
       " [300, 296],\n",
       " [310, 436],\n",
       " [312, 0],\n",
       " [324, 26],\n",
       " [356, 38],\n",
       " [363, 283],\n",
       " [370, 29],\n",
       " [378, 270],\n",
       " [384, 59],\n",
       " [385, 270],\n",
       " [387, 31],\n",
       " [390, 289],\n",
       " [393, 334],\n",
       " [394, 160],\n",
       " [399, 159],\n",
       " [408, 253],\n",
       " [418, 265],\n",
       " [426, 149],\n",
       " [427, 244],\n",
       " [429, 244],\n",
       " [451, 154],\n",
       " [460, 245],\n",
       " [465, 364],\n",
       " [466, 310],\n",
       " [473, 266],\n",
       " [476, 187],\n",
       " [477, 185],\n",
       " [480, 325],\n",
       " [481, 234],\n",
       " [485, 201],\n",
       " [490, 374],\n",
       " [491, 359]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_corr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check collinearity of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if 3 points are collinear - if true: can't be used to calculate homography matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_2_vectors_collinear(vec1,vec2,eps = 1e-6):\n",
    "    if_collinear = False\n",
    "    vec1_norm = np.linalg.norm(vec1)\n",
    "    vec2_norm = np.linalg.norm(vec2)\n",
    "    if vec1_norm>eps and vec2_norm>eps: \n",
    "        vec_dot = np.dot(vec1,vec2)/vec1_norm/vec2_norm\n",
    "        if abs(vec_dot-1)<=eps:\n",
    "            if_collinear = True\n",
    "    return if_collinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_3collinear_in_set(sample_set, kp, eps = 1e-6):\n",
    "    '''\n",
    "    check if any 3 points in a set (e.g. 4 points for homograpy) is collinear\n",
    "    which is inappropriate to find homography matrix\n",
    "    \n",
    "    Through dot product for 2 dimensional.\n",
    "    ps: cos(0 grad) = 1\n",
    "    eps (by def) = 10^(-6)\n",
    "    \n",
    "    Input:\n",
    "        'sample_set' - 4 points from 1 image to find homography matrix\n",
    "        'kp' - key points from set\n",
    "        'eps' - accuracy, 10^(-6) by default\n",
    "    \n",
    "    Return:\n",
    "        'if_collinear' - boolean if there is a 3 point on one line\n",
    "    '''\n",
    "    \n",
    "    # get points from kp\n",
    "    points = []\n",
    "    for point_num in sample_set:\n",
    "        points.append(kp[point_num])\n",
    "    \n",
    "    # for each combination of 3 points find collinear\n",
    "    if_collinear = False\n",
    "    for three_points in itertools.combinations(points,3):\n",
    "        vec1 = np.array(three_points[1].pt)-np.array(three_points[0].pt)\n",
    "        vec2 = np.array(three_points[2].pt)-np.array(three_points[0].pt)\n",
    "        \n",
    "        if_collinear = if_2_vectors_collinear(vec1,vec2,eps)\n",
    "        if if_collinear:\n",
    "            break\n",
    "    return if_collinear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine ERROR measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_by_angle(vec_0,vec_1): \n",
    "    \n",
    "    ''' If we use distance as angle between 2 vectors '''\n",
    "\n",
    "    vec_0_norm = vec_0/np.linalg.norm(vec_0)\n",
    "    vec_1_norm = vec_1/np.linalg.norm(vec_1)\n",
    "    \n",
    "    cross_prod = np.dot(vec_0_norm,vec_1_norm.T)\n",
    "    cross_prod = 0.9999*cross_prod\n",
    "    \n",
    "    distance_angle = np.arccos(cross_prod)\n",
    "    \n",
    "    return distance_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_error(h,sample,kp_0,kp_1,mutual_corr_list,dist = 'angle'):\n",
    "    '''\n",
    "    Calculate total error for all points based on given homography matrix\n",
    "    \"dist\" - must be \"angle\" or \"norm\"\n",
    "    '''\n",
    "    assert dist in [\"angle\",\"norm\"],(\"Expected 'angle' or 'norm'\")\n",
    "    distances = []\n",
    "    for i,j in mutual_corr_list:\n",
    "        kp_0_h = np.array((kp_0[i].pt[0],kp_0[i].pt[1],1), dtype = \"float64\").dot(h)\n",
    "        kp_0_h = np.array((kp_0_h[0]/kp_0_h[2],kp_0_h[1]/kp_0_h[2],1), dtype = \"float64\")\n",
    "        kp_1_orig = np.array((kp_1[j].pt[0],kp_1[j].pt[1],1), dtype = \"float64\")\n",
    "        \n",
    "        if dist == 'norm':\n",
    "            distance = cv2.norm(kp_0_h,kp_1_orig)\n",
    "        else:\n",
    "            distance = dist_by_angle(kp_0_h,kp_1_orig)\n",
    "        \n",
    "        distances.append(distance)\n",
    "        \n",
    "    return sum(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints_pt_by_sample(kp_0,kp_1,sample):\n",
    "    '''\n",
    "    Given list of points, return list of their coordinates to calculate homography matrix\n",
    "    '''\n",
    "    kp_0_sample=[]\n",
    "    kp_1_sample=[]\n",
    "    for i,j in sample:\n",
    "        kp_0_sample.append(kp_0[i].pt)\n",
    "        kp_1_sample.append(kp_1[j].pt)\n",
    "    return kp_0_sample, kp_1_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANSAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Sampling Consensus\n",
    "\n",
    "1. Randomly choose 4 points in the first image and 4 point in the second image (avoid using same points and use mutual_corr_list to choose from) \n",
    "1. Calculate Homography matrix\n",
    "1. Calculate inliers\n",
    "1. Repeat until needed accuracy and precision are reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_4_different_pairs(mutual_corr_list):\n",
    "    sample_set_1 = set()\n",
    "    sample_set_2 = set()\n",
    "    \n",
    "    while True:\n",
    "        sample = random.sample(mutual_corr_list,4)\n",
    "        sample_set_1.clear()\n",
    "        sample_set_2.clear()\n",
    "        for i,j in sample:\n",
    "            sample_set_1.add(i)\n",
    "            sample_set_2.add(j)\n",
    "        if len(sample_set_1) ==4 and len(sample_set_2)==4: \n",
    "            if not if_3collinear_in_set(sample_set_1, kp_0) and not if_3collinear_in_set(sample_set_2, kp_1):\n",
    "                break\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ransac_req_iter_num(e=0.5,s=4,p=0.99):\n",
    "    #e - probability that a point is an outlier\n",
    "    #s - number of points in the sample: 4 is for homography\n",
    "    #p - desired probability that we got good sample\n",
    "    iter_num_required = log(1-p)/log(1-(1-e)**s)\n",
    "    req_iter = int(iter_num_required)+1\n",
    "    return req_iter\n",
    "\n",
    "def get_inliers(h, sample, kp_0, kp_1, mutual_corr_list, threshold, dist):\n",
    "    '''\n",
    "    calculate inliers for points not in sample, but can I calculate and for the sample points?\n",
    "    '''\n",
    "    appropriate = []\n",
    "    for i,j in mutual_corr_list:\n",
    "        kp_1_h = h.dot(np.array((kp_1[j].pt[0], kp_1[j].pt[1], 1), dtype = \"float64\"))\n",
    "        kp_1_h /= kp_1_h[2]\n",
    "        kp_0_orig = np.array((kp_0[i].pt[0], kp_0[i].pt[1], 1), dtype = \"float64\")\n",
    "        \n",
    "        if dist == 'norm':\n",
    "            distance = cv2.norm(kp_1_h - kp_0_orig)\n",
    "        else:\n",
    "            distance = dist_by_angle(kp_0_h,kp_1_orig)\n",
    "        \n",
    "        if distance <= threshold:\n",
    "            appropriate.append(distance)\n",
    "    return appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac_find_homography_matrix(kp_0, kp_1, mutual_corr_list,threshold, iter_num_required=0,\n",
    "                                  dist = 'norm', inliers_error = 'inliers'):\n",
    "    '''\n",
    "    0) calculate required number of iterations\n",
    "    repeat for required number of iterations:\n",
    "    1) get sample of kps\n",
    "    2) calculate Homography matrix\n",
    "    3) calculate inliers|total error\n",
    "    4) save the matrix with higher number of matchinliers|lower total error\n",
    "    '''\n",
    "    # 0\n",
    "    if iter_num_required == 0:\n",
    "        iter_num_required = get_ransac_req_iter_num()\n",
    "    # print(kp_0)\n",
    "    # kp_0 = np.array([kp_0[i].pt for i, _ in mutual_corr_list])\n",
    "    # kp_1 = np.array([kp_1[i].pt for _, i in mutual_corr_list])\n",
    "    # best_homography, _ = cv2.findHomography(kp_1, kp_0, cv2.RANSAC, threshold)\n",
    "\n",
    "    best_homography = []\n",
    "    max_inliers_num = 0 \n",
    "    total_error_min = -1\n",
    "    for x in range(iter_num_required):\n",
    "        # 1\n",
    "        sample = get_4_different_pairs(mutual_corr_list)\n",
    "        # print('Sample is: {}'.format(sample))\n",
    "        kp_0_sample, kp_1_sample = get_keypoints_pt_by_sample(kp_0,kp_1,sample)\n",
    "        # 2\n",
    "        h, status = cv2.findHomography(np.array(kp_1_sample), np.array(kp_0_sample), 10**6)\n",
    "        \n",
    "        # 3\n",
    "        if inliers_error == 'inliers':\n",
    "            inliers_dist = get_inliers(h,sample,kp_0,kp_1,mutual_corr_list,threshold, dist)\n",
    "            curr_inliers_num = len(inliers_dist)\n",
    "            if max_inliers_num < curr_inliers_num:\n",
    "                print(f'Change of model!!!\\nPrevious max_inliers_num: {max_inliers_num} \\nCurrent curr_inliers_num: {curr_inliers_num}')\n",
    "                max_inliers_num = curr_inliers_num\n",
    "                best_homography = h\n",
    "        \n",
    "    #     if inliers_error == 'error':\n",
    "    #         total_error = get_total_error(h,sample,kp_0,kp_1,mutual_corr_list, dist)\n",
    "    #         # print(f'total_error = {total_error}')\n",
    "    #         if total_error_min ==-1:\n",
    "    #             total_error_min = total_error\n",
    "    #         else:\n",
    "    #             if total_error_min > total_error:\n",
    "    #                 total_error_min = total_error\n",
    "    #                 best_homography = h\n",
    "        \n",
    "    print(f'Maximum inliers: {max_inliers_num}',f'Total error min: {total_error_min}', f'Best homography: {best_homography}', sep = '\\n')\n",
    "    return best_homography, total_error_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change of model!!!\n",
      "Previous max_inliers_num: 0 \n",
      "Current curr_inliers_num: 8\n",
      "Change of model!!!\n",
      "Previous max_inliers_num: 8 \n",
      "Current curr_inliers_num: 13\n",
      "Change of model!!!\n",
      "Previous max_inliers_num: 13 \n",
      "Current curr_inliers_num: 14\n",
      "Change of model!!!\n",
      "Previous max_inliers_num: 14 \n",
      "Current curr_inliers_num: 45\n",
      "Maximum inliers: 45\n",
      "Total error min: -1\n",
      "Best homography: [[ 8.28440011e-01 -3.15950215e-02  4.03062325e+02]\n",
      " [-1.81552537e-01  9.87680882e-01 -1.12336252e+01]\n",
      " [-2.97831913e-04  1.22085370e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "h, error = ransac_find_homography_matrix(kp_0, kp_1, mutual_corr_list, threshold, iter_num_required=0, dist = \"norm\",inliers_error='inliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.all(h) != 0: \n",
    "    img_1_after_homography = imgs[2].copy()\n",
    "    result = cv2.warpPerspective(img_1_after_homography, h, (imgs[0].shape[1]+imgs[1].shape[1],imgs[1].shape[0]))\n",
    "    coco=cv2.imwrite(os.path.join(path_results,'warped',f'{path_source}_img000_warped_before_sift.jpg'),result)\n",
    "    result[:imgs[1].shape[0],:imgs[1].shape[1]]=imgs[1]\n",
    "    coco2=cv2.imwrite(os.path.join(path_results,'warped',f'{path_source}_img000_warped_after_sift.jpg'),result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if np.all(h) != 0: \n",
    "    img_0_after_homography = imgs[0].copy()\n",
    "    img_0_after_homography = cv2.warpPerspective(img_0_after_homography, h, (imgs[1].shape[1],imgs[1].shape[0]))\n",
    "\n",
    "    cv2.imwrite(os.path.join(path_results,'warped',f'{path_source}_img000_warped_sift_{error}.jpg'),img_0_after_homography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
